# LLM-Fine-Tuning
Two types of fine Tuning using kerasnlp and Pytorch using QLORA technique on custom data  

Finetuning using Mistral with QLora and PEFt  
---
This section provides a guide on how to perform finetuning using Mistral with QLora and PEFt. The process involves the following steps:

Setup Environment: Ensure that your environment is set up with all the necessary dependencies for Mistral, QLora, and PEFt.
Prepare Data: Prepare your dataset for finetuning. This involves preprocessing your data into a suitable format for training.
Configure Finetuning Parameters: Set up the finetuning parameters, including the learning rate, batch size, and the number of epochs.
Initiate Finetuning: Start the finetuning process using Mistral with the QLora and PEFt configurations.
Evaluate Model: After finetuning, evaluate the performance of your model on a validation set to ensure that it meets your expectations.
Deploy Model: Once satisfied with the model's performance, you can deploy it for inference.
For a detailed demonstration of the finetuning process using Mistral, QLora, and PEFt, refer to the notebook Fine_Tuning_with_Mistral_QLora_PEFt.ipynb included in this repository.



1 - [Fine tuning LLMA model](https://github.com/MAHMOUDRR707/LLM-Fine-Tuning/blob/master/Fine_tuning_with_LLM.ipynb)

2 - [Fine tuning Gemma model](https://github.com/MAHMOUDRR707/LLM-Fine-Tuning/blob/master/Fine_Tune_Gemma_with_kerasNLP.ipynb)



![img](https://cdn.prod.website-files.com/640f56f76d313bbe39631bfd/65358e7d97cd72e210afa0bd_lora-qlora.png)

Reference of keras NLP LIbrary , Pytorch , Hugging Face , Keras's turtorial on Kaggle and krishnaik06
